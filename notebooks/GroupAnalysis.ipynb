{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Analysis\n",
    "\n",
    "Notes\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "\n",
    "from hypertools.tools.align import align\n",
    "\n",
    "# Classification stuff\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Note: Decode both to the stimulus, and to the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Settings\n",
    "k_fold = 3\n",
    "\n",
    "# Initialize SVM classification object\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "# Set the expected number of events per condition\n",
    "expected_ev_counts = [25, 25]\n",
    "\n",
    "# Set data size\n",
    "n_epochs = 50\n",
    "n_chs = 181\n",
    "n_times = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dat(dat):\n",
    "    \"\"\"Organize data for classification. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dat : mne.Epochs object\n",
    "        A subject's worth of epoched data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    labels : 1d array\n",
    "        xx\n",
    "    data : 3d array\n",
    "        xx\n",
    "    \"\"\"\n",
    "\n",
    "    # Check event codes there are, and unpack\n",
    "    ev_counts = Counter(dat.events[:, 2])\n",
    "    evc_a, evc_b = [str(el) for el in ev_counts.keys()]\n",
    "    n_evc_a, n_evc_b = ev_counts.values()\n",
    "\n",
    "    # Check the number of events is as expected\n",
    "    if [n_evc_a, n_evc_b] != expected_ev_counts:\n",
    "        raise ValueError('Number of events does not match what was expected.')\n",
    "        \n",
    "    # Generate labels\n",
    "    labels = np.hstack([np.zeros(shape=[n_evc_a]), np.ones(shape=[n_evc_b])])\n",
    "    \n",
    "    # Organize data\n",
    "    data = np.concatenate([dat[evc_a]._data, dat[evc_b]._data], 0)\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def extract_data(data_lst, flatten=False, transpose=False):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_lst : list of mne.Epochs objects\n",
    "        xx\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_data : list of arrays\n",
    "        xx\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract data matrices from MNE object\n",
    "    all_data = [obj._data for obj in data_lst]\n",
    "    \n",
    "    # Flatten into continuous (2D) representation\n",
    "    if flatten:\n",
    "        all_data = [np.concatenate(dat, 1) for dat in all_data]\n",
    "    \n",
    "    # Transpose from [channels x features] to [features x channels]\n",
    "    if flatten & transpose:\n",
    "        all_data = [dat.T for dat in all_data]\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "    # Note: flatten & transpose both True is equivalent to:\n",
    "    # all_data = [np.reshape(obj._data,\n",
    "    #                        [obj._data.shape[1],\n",
    "    #                         obj._data.shape[0] * obj._data.shape[2]]\n",
    "    #                       ).T for obj in all_subjs]\n",
    "\n",
    "\n",
    "def revert_3d(data_lst):\n",
    "    \"\"\"Reorganize a 2d matrix into the 3D trial structure.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    Results\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    return [np.reshape(dat, [n_epochs, n_chs, n_times ]) for dat in data_lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Organization / Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set data location for processed files\n",
    "dat_path = '/Users/tom/Desktop/HyperEEG_Project/Data/proc/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get list of available files\n",
    "dat_files = [file for file in os.listdir(dat_path) if '.fif' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "all_subjs = [mne.read_epochs(os.path.join(dat_path, f_name),\n",
    "                            preload=True, verbose=False) for f_name in dat_files]\n",
    "\n",
    "# Check how many subjects there are\n",
    "n_subjs = len(all_subjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # TESTS\n",
    "\n",
    "# # Load single subject data\n",
    "dat = mne.read_epochs(os.path.join(dat_path, dat_files[0]), preload=True, verbose=False)\n",
    "\n",
    "# Make test list of multi-subj data\n",
    "all_subjs = [dat, dat, dat]\n",
    "n_subjs = len(all_subjs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Within Subject Classification (un-aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the \n",
    "\n",
    "avg = np.max\n",
    "#avg = np.min\n",
    "#avg = np.mean\n",
    "#avg = np.median\n",
    "\n",
    "# n_times = len(dat.times)\n",
    "# half_t = int(n_times/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize subject data for classification\n",
    "data, labels = prep_dat(dat)\n",
    "\n",
    "# Optionally: sub-select features\n",
    "data = avg(data[:, 0:128, :], 2)\n",
    "#data = avg(data[:, 0:128, 0:half_t], 2)\n",
    "#data = avg(data[:, 0:128, half_t:], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run cross-validated classification\n",
    "scores = cross_val_score(clf, data, labels, cv=k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated prediction: 63.66%\n"
     ]
    }
   ],
   "source": [
    "# Check outcome\n",
    "print('Cross-Validated prediction: {:1.2f}%'.format(np.mean(scores) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Between Subject Classification (un-aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data, all_labels = [], []\n",
    "for subj in all_subjs:\n",
    "    data, labels = prep_dat(subj)\n",
    "    all_data.append(data)\n",
    "    all_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def btwn_subj_classication(all_data, all_labels):\n",
    "    \"\"\"Run classification between subjects.\"\"\"\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for ind, subj_data, subj_labels in zip(range(len(all_data)), all_data, all_labels):\n",
    "\n",
    "        # Take a copy of the group data, and drop held out subject\n",
    "        temp_data = deepcopy(all_data)\n",
    "        temp_labels = deepcopy(all_labels)\n",
    "        del temp_data[ind]\n",
    "        del temp_labels[ind]\n",
    "\n",
    "        # Collapse group for training the model\n",
    "        group_data = np.concatenate(temp_data, 0)\n",
    "        group_labels = np.concatenate(temp_labels, 0)\n",
    "\n",
    "        group_data = avg(group_data[:, 0:128, :], 2)\n",
    "\n",
    "        # Train on group & classify left out subject\n",
    "        clf = svm.SVC(kernel='linear')\n",
    "        clf.fit(group_data, group_labels)\n",
    "        scores.append(clf.score(avg(subj_data[:, 0:128, :], 2), subj_labels))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57999999999999996, 0.57999999999999996, 0.57999999999999996]\n",
      "0.58\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "btwn_scores = btwn_subj_classication(all_data, all_labels)\n",
    "print(btwn_scores)\n",
    "print(np.mean(btwn_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data organization - extract matrices, and flatten to continuous data\n",
    "#  Note: this also switches orientation (takes the transpose) to match hypertools\n",
    "all_data = extract_data(all_subjs, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do alignment\n",
    "aligned_dat = align(all_data)\n",
    "aligned_dat = [dat.T for dat in aligned_dat]\n",
    "aligned_dat = revert_3d(aligned_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Between Subject Classification (aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.56000000000000005, 0.56000000000000005, 0.56000000000000005]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btwn_subj_classication(aligned_dat, all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Victory Party."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
